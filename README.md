This repo contains the code for the Temporal Ordering project submitted to SC2022.
The directories each contain a step of the pipeline or some helper code.

### Date Extraction using the Weighted String Automaton

The best entry point for extracting dates with the weighted string automaton approach
is in `segment_labeling`. The folder's README contains all the necessary information.

### Date Extraction using ML

For a training and evaluation run of the model, call `date_extraction.Model.run()`.
Parameters like number of epochs or batch size can be changed in the script. Running
the model like this will only use a small data sample provided in 
`synth_data_embs.jsonl`, which contains the BERT embeddings of 1000 synthesized
date occurrences and the date label. To run the model with more data, the following
steps are necessary:
1. Download the datasets listed in `data_preprocessing`. If you don't want to use
all of them, remove the line loading it in `data_preprocessing/merge_datasets.py`.
2. Add the paths to the datasets to `data_preprocessing/merge_datasets.py` and
run the script
3. Run `data_synthesis.Synthesize.synthesize_data()` to generate synthetic labeled
data. Pass the file generated by the previous step (named `articles.json` by default).
This may take a while and can be sped up by using `SynthesizeMPI.py` instead,
which requires MPI. See the README in `data_synthesis` for details. The 
provided `synth_data_embs.jsonl` will be overwritten.

### Dependencies

Dependencies can be easily installed by using conda. Execute 
`conda env create -f conda_env.yaml` to setup the environment.
This will also install a specific version of CUDA toolkit and PyTorch. These might
need to be changed to work.